{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8958a9c-76a0-4209-9dfa-5c832d8fa07c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!apt install -y ffmpeg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce74c237-493e-4f88-bad7-b613262b378a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0b9c81c-70bc-436d-bed1-3a6d11f84950",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#List of dependencies\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "\n",
    "# from fuzzywuzzy import fuzz\n",
    "# from fuzzywuzzy import process\n",
    "import difflib\n",
    "## mp4 to .wav converter\n",
    "import ffmpeg\n",
    "\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "SPEECH_REGION = \"xxxx\"\n",
    "SPEECH_KEY=\"xxxx\"\n",
    "\n",
    "#####################################################################################\n",
    "############################## GLOBAL VARIABLE SETTING #############################\n",
    "#####################################################################################\n",
    "if not('IS_FIRST_NOTEBOOK_RUN' in locals()):\n",
    "#     os.system(\"apt-get -f -y install xxxxx\")\n",
    "    IS_FIRST_NOTEBOOK_RUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46c0a0a3-456f-4502-a7f7-16f415c6e921",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "\u001B[0;32m<command-2936792143812905>\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[0;31m#formats_to_convert = ['.m4a']\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m----> 5\u001B[0;31m \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdbutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwidgets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'filename'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;31m#define the filename ###.aac. m4a ...\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\".\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'csv'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'txt'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m     40\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mCurrent\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mwidget\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mdefault\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     41\u001B[0m         \"\"\"\n",
       "\u001B[0;32m---> 42\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_notebookArguments\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetArgument\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_entry_point\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetCurrentBindings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     44\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mgetArgument\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefaultValue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n",
       "\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n",
       "\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    194\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    195\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 196\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    197\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    198\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n",
       "\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o343.getArgument.\n",
       ": com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named filename is defined\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n",
       "\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:258)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:306)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n",
       "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n\u001B[0;32m<command-2936792143812905>\u001B[0m in \u001B[0;36m<cell line: 5>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#formats_to_convert = ['.m4a']\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdbutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwidgets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'filename'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mfilename\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;31m#define the filename ###.aac. m4a ...\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\".\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m'csv'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m'txt'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python_shell/dbruntime/WidgetHandlerImpl.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0;34m:\u001B[0m\u001B[0;32mreturn\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mCurrent\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mwidget\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mdefault\u001B[0m \u001B[0mvalue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     41\u001B[0m         \"\"\"\n\u001B[0;32m---> 42\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_notebookArguments\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetArgument\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_entry_point\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgetCurrentBindings\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     44\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mgetArgument\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdefaultValue\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1319\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1320\u001B[0m         \u001B[0manswer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgateway_client\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msend_command\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcommand\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1321\u001B[0;31m         return_value = get_return_value(\n\u001B[0m\u001B[1;32m   1322\u001B[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001B[1;32m   1323\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/pyspark/sql/utils.py\u001B[0m in \u001B[0;36mdeco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    194\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdeco\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 196\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0ma\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkw\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    197\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mPy4JJavaError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    198\u001B[0m             \u001B[0mconverted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjava_exception\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\u001B[0m in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m             \u001B[0mvalue\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOUTPUT_CONVERTER\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgateway_client\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    325\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0manswer\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mREFERENCE_TYPE\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 326\u001B[0;31m                 raise Py4JJavaError(\n\u001B[0m\u001B[1;32m    327\u001B[0m                     \u001B[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    328\u001B[0m                     format(target_id, \".\", name), value)\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o343.getArgument.\n: com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named filename is defined\n\tat com.databricks.backend.daemon.driver.NotebookArguments.checkExists(NotebookArguments.scala:72)\n\tat com.databricks.backend.daemon.driver.NotebookArguments.getArgument(NotebookArguments.scala:258)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:306)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:195)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:115)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "com.databricks.dbutils_v1.InputWidgetNotDefined: No input widget named filename is defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pydub import AudioSegment\n",
    "import argparse\n",
    "import base64\n",
    "\n",
    "#formats_to_convert = ['.m4a']\n",
    "filename = dbutils.widgets.get('filename')\n",
    "\n",
    "\n",
    "decoded_bytes = base64.b64decode(filename)\n",
    "filename = decoded_bytes.decode('utf-8')\n",
    "\n",
    "\n",
    "filename = filename.split(\"/\")[1] #define the filename ###.aac. m4a ...\n",
    "if filename.split(\".\")[0] not in ['csv','txt']:\n",
    "\n",
    "    #if filename.endswith(tuple(formats_to_convert)):\n",
    "    filepath = PATH+\"audio_files\"+\"/\" + filename\n",
    "    (path, file_extension) = os.path.splitext(filepath)\n",
    "    file_extension_final = file_extension.replace('.', '')\n",
    "    try:\n",
    "        if file_extension_final == 'opus':\n",
    "            track = AudioSegment.from_file(filepath, format=\"ogg\", codec=\"libopus\")\n",
    "        else:\n",
    "            track = AudioSegment.from_file(filepath, file_extension_final)\n",
    "\n",
    "        wav_filename = filename.replace(file_extension_final, 'wav')\n",
    "        wav_path = PATH+'audio_wav_files/' + wav_filename\n",
    "        file_handle = track.export(wav_path, format='wav')\n",
    "        print('CONVERTING: ' + str(filepath))\n",
    "        while not os.path.exists(wav_path):\n",
    "            print(wav_path)\n",
    "            file_handle = track.export(wav_path, format='wav')\n",
    "    except:\n",
    "        print(\"ERROR CONVERTING \" + str(filepath))\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fe5504b-e315-4746-9ca8-082f36f0b664",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6203de61-fa2b-405a-80f0-bb81f6321a4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#https://learn.microsoft.com/en-us/azure/cognitive-services/speech-service/batch-transcription-get?pivots=rest-api\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "subscription_key=\"xxxx\"\n",
    "contenturl = '\"xxxx\"' + wav_filename\n",
    "# contentsasurl = contenturl + '?' + sas_token\n",
    "region =  \"eastasia\"\n",
    "endpoint = f\"\"xxxx\"\"\n",
    "\n",
    "def request_post(subscription_key,contenturl):\n",
    "\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key,\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    # Set the request payload\n",
    "    payload = {\n",
    "        \"contentUrls\": [\n",
    "            contenturl,\n",
    "        ],\n",
    "        \"locale\": \"ja-JP\",\n",
    "        \"displayName\": \"My Transcription\",\n",
    "        \"model\": None,\n",
    "        \"properties\": {\n",
    "            \"diarizationEnabled\":True,\n",
    "            \"wordLevelTimestampsEnabled\": True,\n",
    "            \"punctuationMode\": \"DictatedAndAutomatic\",\n",
    "            \"profanityFilterMode\": \"Masked\",\n",
    "            \"diarization\": {\n",
    "                \"speakers\": {\n",
    "                    \"minCount\": 2,\n",
    "                    \"maxCount\": 3}\n",
    "                    }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Send the POST request\n",
    "    response = requests.post(endpoint, headers=headers, json=payload)\n",
    "\n",
    "    # Check the response status\n",
    "    if response.status_code == 201:\n",
    "        print(\"Transcription request submitted successfully.\")\n",
    "        # Extract the transcription ID from the response headers\n",
    "        location_header = response.headers.get(\"location\")\n",
    "        if location_header:\n",
    "            transcription_id = location_header.split(\"/\")[-1]\n",
    "            return transcription_id\n",
    "        else:\n",
    "            return \"Error submitting transcription request.\"\n",
    "    else:\n",
    "        return \"Error submitting transcription request.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8628cba-03a4-496d-ad5e-28557a1f0586",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_response(transcription_id): #successed or not\n",
    "    endpoint = f\"\"xxxx\"/{transcription_id}\"\n",
    "\n",
    "    # Set the request headers\n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": subscription_key\n",
    "    }\n",
    "\n",
    "    # Send the GET request\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "    # Check the response status\n",
    "    if response.status_code == 200:\n",
    "        # Get the result files from the response JSON\n",
    "        status = response.json()['status'] \n",
    "        return status\n",
    "    else:\n",
    "        return \"Error retrieving result files_Step_1.\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "804f605f-8b6a-4d6b-b649-6d1b21373768",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_files(transcription_id): \n",
    "    endpoint = f\"\"xxxx\"/{transcription_id}/files\"\n",
    "\n",
    "    # Set the request headers\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": subscription_key}\n",
    "    # Send the GET request\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    # Check the response status\n",
    "    if response.status_code == 200:\n",
    "        # Get the result files from the response JSON\n",
    "        result_files = response.json()\n",
    "        return result_files\n",
    "    else:\n",
    "        return \"Error retrieving result files.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24889ecd-7f5d-4428-a053-dd70a3757f8e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_link_content(results):\n",
    "    # JSON link\n",
    "    json_url = results['values'][0]['links']['contentUrl']\n",
    "\n",
    "    # Make an HTTP GET request\n",
    "    link_response = requests.get(json_url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if link_response.status_code == 200:\n",
    "        # Retrieve the JSON data\n",
    "        json_data = link_response.json()\n",
    "        return json_data\n",
    "\n",
    "    else:\n",
    "        return \"Failed to retrieve JSON data. Status code:\" + link_response.status_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4827ff55-bbff-47f5-b76f-24d209632424",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def content(content_json):\n",
    "    try:\n",
    "        content_json = get_link_content(results)\n",
    "        content_json = content_json['recognizedPhrases']\n",
    "\n",
    "        output = []\n",
    "        previous_speaker = None\n",
    "        if len(content_json) > 0:\n",
    "            for i in range(len(content_json)):\n",
    "                speaker = content_json[i]['speaker']\n",
    "                text = content_json[i]['nBest'][0]['display']\n",
    "\n",
    "                if speaker == previous_speaker:\n",
    "                    output[-1] += \" \" + \"Speaker \" + str(speaker) + \": \" + text\n",
    "                else:\n",
    "                    output.append(\"Speaker \" + str(speaker) + \": \" + text)\n",
    "                \n",
    "                previous_speaker = speaker\n",
    "\n",
    "        content_output = \"\\n\".join(output)\n",
    "        return content_output\n",
    "\n",
    "    except:\n",
    "        return 'Error to get link_content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04fe983a-ee3e-43bc-9a87-272001616d9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription request submitted successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "request_post = request_post(subscription_key,contenturl)\n",
    "if request_post != \"Error submitting transcription request.\":\n",
    "    transcription_id = request_post\n",
    "\n",
    "    if get_response(transcription_id) != \"Error retrieving result files_Step_1.\":\n",
    "        times = 0\n",
    "        while times < 20:\n",
    "            if get_response(transcription_id) == 'Succeeded':\n",
    "                results = get_files(transcription_id)\n",
    "                break\n",
    "            else:\n",
    "                time.sleep(30)\n",
    "                continue\n",
    "                times += 1\n",
    "        if results != \"Error retrieving result files.\":\n",
    "            content_json = get_link_content(results)\n",
    "            if content(content_json) != 'Error to get link_content':\n",
    "                content = content(content_json)\n",
    "            else:\n",
    "                print('Error to get link_content')\n",
    "        else:\n",
    "            print(\"Error retrieving result files.\")\n",
    "    else:\n",
    "        print(\"Error retrieving result files_Step_1.\")\n",
    "else:\n",
    "    print(\"Error for request submit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ef5f63f-e774-4d05-ac83-3334a856262d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(PATH+'transcript_for_each_audio/'+filename[:-4]+\".txt\", 'w') as f: #overwrite the file if it existing\n",
    "    if content == 0:\n",
    "        content= \"\"\n",
    "    f.write(content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74c68d1a-493e-4ee6-af68-4ec78b90ce41",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#OpenAI Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b51904f4-c953-404d-8efe-45db62d52fad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url=\"xxxx\"\n",
    "\n",
    "payload = json.dumps({\n",
    "\"user\": \"[User GAD]\",\n",
    "\"model\":\"gpt-35-turbo\",\n",
    "\"messages\": [\n",
    "{\n",
    "\"role\": \"system\",\n",
    "\"content\": \"You are a helpful assistant.\"\n",
    "},\n",
    "{\n",
    "\"role\": \"user\",\n",
    "\"content\": f\"\"\"\"xxxx\" \"\"\"\n",
    "}\n",
    "]\n",
    "})\n",
    "\n",
    "client_key=\"xxxx\"\n",
    "client_secret=\"xxxx\"\n",
    "\n",
    "id_secret_bytes = client_key + ':' + client_secret\n",
    "encoded_u = base64.b64encode(id_secret_bytes.encode()).decode()\n",
    "headers = {\"Authorization\": \"Basic %s\" % encoded_u, 'Content-type': 'application/json', 'Accept': 'application/json'}\n",
    "\n",
    "r=requests.post(url,headers=headers,data=payload)\n",
    "print(\"RESPONSE\"+r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7347ea85-0683-4236-94ab-9f9f54ce2aa0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "content_summary = r.json()['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f5027b7-aa2a-4f20-b360-e4cedd5644c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "content_with_summary = content + \"\\n\" + \"Conservation_Summary:\" + content_summary\n",
    "with open(PATH +'transcript_for_each_audio/' +filename[:-4]+\".txt\", 'w') as f: #overwrite the file if it existing\n",
    "    if content == 0:\n",
    "        content= \"\"\n",
    "    f.write(content_with_summary)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cace01b-3b56-47f7-9f35-ff1c49ec4850",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timedelta, timezone\n",
    "\n",
    "df_file_time = pd.DataFrame(columns = ['FileName','FileTime'])\n",
    "for (dirpath, dirnames, filenames) in os.walk(PATH+\"audio_files\"+\"/\"):\n",
    "    for filename in filenames:\n",
    "        if filename.split('.')[1] not in ['csv','txt']:\n",
    "            filepath = dirpath + filename\n",
    "            filetime = os.path.getctime(filepath)\n",
    "            \n",
    "filename_list = []\n",
    "filetime_list = []\n",
    "TAT_list = []\n",
    "now = datetime.now()\n",
    "for (dirpath, dirnames, filenames) in os.walk(PATH+\"audio_files\"+\"/\"):\n",
    "    for filename in filenames:\n",
    "        if filename.split('.')[1] not in ['csv','txt']:\n",
    "            filename_list.append(filename.split(\".\")[0])\n",
    "            filepath = dirpath + filename\n",
    "            filetime = os.path.getctime(filepath)\n",
    "            filetime = datetime.fromtimestamp(filetime)\n",
    "            # Create the UTC+7 timezone\n",
    "            utc_plus_7 = timezone(timedelta(hours=7))\n",
    "            filetime = filetime.astimezone(utc_plus_7)\n",
    "            time_gap = now.timetuple().tm_yday - filetime.timetuple().tm_yday\n",
    "            filetime = filetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            filetime_list.append(filetime)\n",
    "            TAT_list.append(time_gap)\n",
    "            \n",
    "df_file_time =  pd.DataFrame({'FileName':filename_list,'FileTime':filetime_list})\n",
    "df_file_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79e8def9-18da-4376-8e63-9cc8ae6490cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#text_folders = os.listdir(PATH)\n",
    "text_folders = os.listdir(PATH +'transcript_for_each_audio/')\n",
    "speech_list = []\n",
    "speech_name = []\n",
    "speech_summary = []\n",
    "\n",
    "for file in text_folders:\n",
    "    split_tup = os.path.splitext(file)\n",
    "    if split_tup[0] != 'temp':\n",
    "        if split_tup[1] == \".txt\":\n",
    "            with open(PATH +'transcript_for_each_audio/'+file) as f:\n",
    "                speech = f.read()\n",
    "            speech_list.append(speech.split('Conservation_Summary:')[0])\n",
    "            try:\n",
    "                speech_summary.append(speech.split('Conservation_Summary:')[1])\n",
    "            except:\n",
    "                speech_summary.append('Error')\n",
    "            speech_name.append(split_tup[0])\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'FileName':speech_name,\n",
    "                  'Text':speech_list,\n",
    "                  'Summary':speech_summary})       \n",
    "\n",
    "\n",
    "df['Manual Review'] = ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87edd517-2561-4057-95b6-a9a50aba85c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#Data to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fd462b1-9fad-42f9-9c5f-061c2a3bfb95",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
    "curl https://packages.microsoft.com/config/ubuntu/16.04/prod.list > /etc/apt/sources.list.d/mssql-release.list \n",
    "apt-get update\n",
    "ACCEPT_EULA=Y apt-get install msodbcsql17\n",
    "apt-get -y install unixodbc-dev\n",
    "sudo apt-get install python3-pip -y\n",
    "pip3 install --upgrade pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50f86edd-9ebd-4a9a-ad84-8acef663bd56",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.put(\"/databricks/init/<YourClusterName>/pyodbc-install.sh\",\"\"\"\n",
    "#!/bin/bash\n",
    "sudo apt-get update\n",
    "sudo apt-get -q -y install unixodbc unixodbc-dev\n",
    "sudo apt-get -q -y install python3-dev\n",
    "/databricks/python/bin/pip install pyodbc\n",
    "\"\"\", True)\n",
    "\n",
    "import urllib\n",
    "import pyodbc\n",
    "for driver in pyodbc.drivers():\n",
    "    print(driver)\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "server = \"xxxx\"\n",
    "database = \n",
    "username = \n",
    "password = \n",
    "\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "odbc_str = 'DRIVER='+driver+';SERVER='+server+';PORT=1433;UID='+username+';DATABASE='+ database + ';PWD='+ password\n",
    "connect_str = 'mssql+pyodbc:///?odbc_connect=' + urllib.parse.quote_plus(odbc_str)\n",
    "engine = create_engine(connect_str)\n",
    "\n",
    "#used to create a table, will overwrite \n",
    "def to_sql(df, table):\n",
    "    df.to_sql(table, engine, if_exists = \"replace\", index=False, chunksize = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e65ca59-6328-4a8a-a2b4-f7869d73f04d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(odbc_str)\n",
    "sql = 'SELECT * FROM [dbo].[\"xxxx\"]'\n",
    "df = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b95936c5-b6d3-4f81-91f2-198baf4d324b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d\")\n",
    "df_result.to_csv(PATH+\"transcript_version\"xxxx\"_\"+now+\".csv\",index=False,encoding='utf-16', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "490b1211-ad5c-42ee-b6e7-5be41c064c27",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "table_name = '\"xxxx\"'\n",
    "cursor = conn.cursor()\n",
    "if cursor.tables(table=table_name, tableType='TABLE').fetchone():\n",
    "    delete_table_query = f\"DROP TABLE {table_name}\"\n",
    "    cursor.execute(delete_table_query)\n",
    "    conn.commit()\n",
    "\n",
    "# Create a new table\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE {table_name} (\n",
    "    FileName NVARCHAR(MAX),\n",
    "    Text NVARCHAR(MAX),\n",
    "    Summary NVARCHAR(MAX),\n",
    "    FileTime VARCHAR(255),\n",
    "    [Manual Review] VARCHAR(255)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()\n",
    "\n",
    "##Insert data\n",
    "insert_query = f\"\"\"\n",
    "INSERT INTO {table_name} (FileName, Text, Summary, FileTime, [Manual Review])\n",
    "VALUES (?, ?, ?, ?, ?)\n",
    "\"\"\"\n",
    "data_tuples = [tuple(row) for row in df_result.to_numpy()]\n",
    "cursor.executemany(insert_query, data_tuples)\n",
    "conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbc784bc-d4c4-48a2-9d5b-4f5730600dea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # create primary key\n",
    "    conn = pyodbc.connect(odbc_str)\n",
    "    cur = conn.cursor()\n",
    "    sql = '''ALTER TABLE \"xxxx\" ADD id INT NOT NULL PRIMARY KEY IDENTITY'''\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "except:\n",
    "    # create primary key\n",
    "    conn = pyodbc.connect(odbc_str)\n",
    "    cur = conn.cursor()\n",
    "    sql = '''ALTER TABLE \"xxxx\" ADD id INT NOT NULL PRIMARY KEY IDENTITY'''\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc97bd1-59e5-41c0-8c87-12d7308ddf9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2936792143812897,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "speech2text_diarization_Main_export",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
