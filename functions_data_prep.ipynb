{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "683eb231-06e4-4226-ab56-d8d99823ed3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "folder_name = 'xxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53108b7b-8fc1-4c8b-9c52-a6e290117895",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Applies wage indexation to hourly rates and gross incurred amounts, \n",
    "# df = data frame with claims data\n",
    "# file = path to file with wage indices\n",
    "# last_quarter_index = string with last quarter for which the index is available/used e.g. '2021Q4'\n",
    "def wage_indexation(df, file):\n",
    "    \"\"\"\n",
    "    Output: (Dataframe)\n",
    "    dataframe with added columns with indexation factors and indexed wages and incurred amounts\n",
    "    _____________________________________________________\n",
    "    Parameters:\n",
    "    df: (Dataframe) Dataframe with claims data\n",
    "    file: (string) Path to the file with the wage index table\n",
    "    \"\"\"\n",
    "    # Load dataset with wage indices\n",
    "    wage_index_df = pd.read_excel(file)\n",
    "    wage_index_df.columns = ['Date','Qrt','WA_index','TAS_index','ACT_index']\n",
    "    wage_index_df = wage_index_df.sort_values(by='Date') # sort by date (earliest first)\n",
    "    last_quarter = max(wage_index_df['Qrt'])\n",
    "    # Complete missing quarters\n",
    "    for y in range((min(pd.DatetimeIndex(wage_index_df['Date']).year)+1),(max(pd.DatetimeIndex(wage_index_df['Date']).year)+1)): # Iterate over all years in index data set\n",
    "        for q in range(1,5): # Iterate over 4 quarters - Note this excludes 5\n",
    "            if wage_index_df['Qrt'][wage_index_df['Qrt']==(str(y)+'Q'+str(q))].count() == 0: # if data doesn't exist for this quarter, take average of adjacent quarters\n",
    "                i_below = wage_index_df[wage_index_df['Qrt'] == (str(y - (5-q) // 4) + 'Q' + str((q-2) % 4 + 1))].index[0]\n",
    "                i_above = wage_index_df[wage_index_df['Qrt'] == (str(y + (q // 4)) + 'Q' + str(q % 4 + 1))].index[0]\n",
    "                df2 = {'Date': np.datetime64((str(y) + '-0' + str((q-1)*3+2) + '-' + str(15) + 'T00:00:00.000')), 'Qrt': (str(y)+'Q'+str(q)), # Create row with new indexes\n",
    "                       'WA_index': (wage_index_df['WA_index'][i_below] + wage_index_df['WA_index'][i_above])/2, \n",
    "                       'TAS_index' : (wage_index_df['TAS_index'][i_below] + wage_index_df['TAS_index'][i_above])/2, \n",
    "                       'ACT_index' : (wage_index_df['ACT_index'][i_below] + wage_index_df['ACT_index'][i_above])/2} \n",
    "                wage_index_df = wage_index_df.append(df2, ignore_index = True) # add extra row with average wage indices\n",
    "    wage_index_df = wage_index_df.sort_values(by='Date')\n",
    "    # Calculate index relative to last_period (currently 2021Q4)\n",
    "    wage_index_df['WA'] = float(wage_index_df[wage_index_df['Qrt']==last_quarter]['WA_index'])/ wage_index_df['WA_index']\n",
    "    wage_index_df['TAS'] = float(wage_index_df[wage_index_df['Qrt']==last_quarter]['TAS_index'])/ wage_index_df['TAS_index']\n",
    "    wage_index_df['ACT'] = float(wage_index_df[wage_index_df['Qrt']==last_quarter]['ACT_index'])/ wage_index_df['ACT_index']\n",
    "    # Convert dateframe to long format for easier merging\n",
    "    wage_index_df_long = pd.melt(wage_index_df, id_vars='Qrt', value_vars=['WA','TAS','ACT']).rename(columns={'variable': 'Risk_State', 'value' : 'indexation_factor'})\n",
    "    \n",
    "    # Merge claim data set and indexation together by LossQuarter and Risk_State\n",
    "    df['LossQuarter'] = pd.PeriodIndex(df['Claim_Loss_Date'], freq='Q').format()\n",
    "    df['Claim_ID'] = range(1,len(df['Claim_Number'])+1)\n",
    "    df = df.merge(wage_index_df_long, left_on=['LossQuarter','Risk_State'], right_on=['Qrt','Risk_State'], how='left')\n",
    "    df['indexation_factor'] = df['indexation_factor'].fillna(1) # Periods after last available index are not indexed\n",
    "    df['Gross_Incurred_Indexed'] = df['Gross_Incurred'] * df['indexation_factor'] # Index gross incurred amount\n",
    "    df['Hourly_Rate_Indexed'] = df['Hourly_Rate_First_13_Weeks_v2'] * df['indexation_factor'] # Index hourly rate\n",
    "    return df\n",
    "\n",
    "# Converts dates in datetime format to number of years (numeric)\n",
    "def convert_date_to_year(dates):\n",
    "    return pd.DatetimeIndex(dates).year + (pd.DatetimeIndex(dates).month - 1)/12 + (pd.DatetimeIndex(dates).day-1)/365 # convert to numeric\n",
    "\n",
    "# Converts dates to a usable numeric format (in years) and calculates differences (in years) for e.g. delays and durations\n",
    "# df = data frame with claims data\n",
    "def clean_dates(df):\n",
    "    df['Claim_Loss_Date_Num'] =convert_date_to_year(df['Claim_Loss_Date'])\n",
    "    df['Inception_Date_Claim_Num'] = convert_date_to_year(df['Inception_Date_Claim'])\n",
    "    df['Inception_Date_Orig_Num'] = convert_date_to_year(df['Policy_Original_Inception_Date']) \n",
    "    df['Expiry_Date_Claim_Num'] =  convert_date_to_year(df['Expiry_Date_Claim'])\n",
    "    df['Policy_Duration'] = df['Expiry_Date_Claim_Num'] - df['Inception_Date_Claim_Num'] # Policy_Duration is diff between expiry and inception date\n",
    "    df['Time_Since_Orig_Policy_Inception'] = df['Claim_Loss_Date_Num'] - df['Inception_Date_Orig_Num']  # Time_Since_Orig_Policy_Inception is diff between loss date and original inception date\n",
    "    df['Claim_Notified_Date_Num'] =  convert_date_to_year(df['Claim_Notified_Date'])\n",
    "    df['Claim_Notified_Delay'] = df['Claim_Notified_Date_Num'] - df['Claim_Loss_Date_Num'] # Claim_Notified_Delay is diff between notified and loss date\n",
    "    df['Liability_Date_Num'] =  convert_date_to_year(df['Liability_Date']) \n",
    "    df['Liability_Delay'] = df['Liability_Date_Num'] - df['Claim_Loss_Date_Num'] # Liability_Delay is diff between liability and loss date\n",
    "    df['Worker_Age'] = df['Claim_Loss_Date_Num'] - convert_date_to_year(df['Worker_Birth_Date'])\n",
    "    df['Work_Resumed_Date_Num'] = convert_date_to_year(df['Work_Resumed_Date'])\n",
    "    df['Work_Resumed_Within_30days_Flag'] = ~df['Work_Resumed_Date'].isna() & ( (df['Work_Resumed_Date_Num'] - df['Claim_Loss_Date_Num'])  <(30/365) ) # Boolean indicating if work has been resumed within 30 days after the accident\n",
    "\n",
    "    df['Worker_Weekly_Hours_Num'] =  pd.to_numeric(df['Worker_Weekly_Hours'].str.replace(\"h \", \".\", regex=True).str.replace(\"m\", \"\", regex=True)) # Convert weekly hours to numeric\n",
    "    df['Worker_Weekly_Hours_Num'] = np.floor(df['Worker_Weekly_Hours_Num']) + (df['Worker_Weekly_Hours_Num'] - np.floor(df['Worker_Weekly_Hours_Num']) )/0.60 # Convert to decimal format (in hours)\n",
    "    df['Weekly_Rate_First13_Indexed'] = df['indexation_factor'] * df['Hourly_Rate_First_13_Weeks_v2'] *  df['Worker_Weekly_Hours_Num'] # calculate weekly rate (note this is the indexed amount)\n",
    "    df['Weekly_Rate_Thereafter_Indexed'] = df['indexation_factor'] * df['Hourly_Rate_Thereafter_v2']\n",
    "    df['Weekly_Rate_Known'] = ~(df['Hourly_Rate_First_13_Weeks_v2'].isna()) & df['Hourly_Rate_First_13_Weeks_v2'] > 0.01 # Boolean flag indicating if weekly rate is known\n",
    "\n",
    "    return (df)\n",
    "\n",
    "# Detrends the gross incurred amounts by on-levelling historic claim amounts to a recent point in time\n",
    "# df = data frame with claims data\n",
    "# detrend_to = string with quarter to which claims are on-levelled e.g. '2021Q4'\n",
    "# detrend_up_to = string wiht last quarter for which sufficiently developed claim amounts are available e.g. '2019Q4'\n",
    "def detrend_incurred(df, onlevel_to_year, last_developed_year):\n",
    "    # Calculate mean loss per year to determine trend (effectively a pivot table)\n",
    "    trend = df.groupby('Claim_Loss_Year')['Gross_Incurred_Indexed'].mean()\n",
    "    temp = trend.to_frame() # convert table to a dataframe\n",
    "    temp['Loss_Year'] = trend.index # rename index to Loss_Year\n",
    "    trend=temp\n",
    "    trend['rate'] = (trend['Gross_Incurred_Indexed']/trend['Gross_Incurred_Indexed'].shift(periods=1)).fillna(1) # Calculate the relative increase in mean loss amount each year\n",
    "    trend['arith_avg'] = (trend['rate'][trend['Loss_Year'] <= last_developed_year]).mean() # Calculate arithmetic average of relative increases each year, use only developed years\n",
    "    trend['geom_avg'] = np.power((trend['rate'][trend['Loss_Year'] <= last_developed_year]).prod(),1/((trend['rate'][trend['Loss_Year'] <= last_developed_year]).size-1)) # Calculate geometric average of relative increases each year, use only developed years\n",
    "    trend['power'] = range((trend['rate'][trend['Loss_Year'] < onlevel_to_year]).size-1,((trend['rate'][trend['Loss_Year'] < onlevel_to_year]).size-1)-trend['rate'].size,-1) # Get # of years between each loss year and the year to onlevel to\n",
    "    trend['detrend_factor'] = trend['geom_avg'].pow(trend['power']) # Get detrend factor to apply to each year for on-levelling\n",
    "    trend['detrended'] = trend['Gross_Incurred_Indexed'] * trend['detrend_factor'] # Apply onleveling factor to get on-leveled mean claim amounts\n",
    "    print(trend) # Print resulting table\n",
    "    # Merge table with detrend factors per year with the claims data set\n",
    "    df = df.merge(trend[['Loss_Year','detrend_factor']], left_on='Claim_Loss_Year', right_on='Loss_Year', how='left')\n",
    "    df['Gross_Incurred_Detrended'] = df['Gross_Incurred_Indexed'] * df['detrend_factor'] # Get onlevelled claim amounts for each individual claim\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def calibrate_detrend_incurred(df, onlevel_to_year, last_developed_year, file_out):\n",
    "    ''' Detrends the gross incurred amounts by on-levelling historic claim amounts to a recent point in time\n",
    "    # df = data frame with claims data\n",
    "    # onlevel_to_year = (int) year to which claims are on-levelled e.g. 2021\n",
    "    # last_developed_year = (int) last year for which sufficiently developed claim amounts are available e.g. 2019\n",
    "    file_out = (string) filename of csv where to save the detrend table\n",
    "    '''\n",
    "    # Calculate mean loss per year to determine trend (effectively a pivot table)\n",
    "    trend = df.groupby('Claim_Loss_Year')['Gross_Incurred_Indexed'].mean()\n",
    "    \n",
    "    temp = trend.to_frame() # convert table to a dataframe\n",
    "    temp['Loss_Year'] = trend.index # rename index to Loss_Year\n",
    "    trend=temp\n",
    "    max_year = max(trend['Loss_Year'])\n",
    "    tmp = pd.DataFrame({'Loss_Year' : list(range(max_year+1, 2051)), \n",
    "                        'Gross_Incurred_Indexed': [1] * (2050-max_year)})\n",
    "    trend = trend.append(tmp, ignore_index=True)\n",
    "    trend['rate'] = (trend['Gross_Incurred_Indexed']/trend['Gross_Incurred_Indexed'].shift(periods=1)).fillna(1) # Calculate the relative increase in mean loss amount each year\n",
    "    trend['arith_avg'] = (trend['rate'][trend['Loss_Year'] <= last_developed_year]).mean() # Calculate arithmetic average of relative increases each year, use only developed years\n",
    "    trend['geom_avg'] = np.power((trend['rate'][trend['Loss_Year'] <= last_developed_year]).prod(),1/((trend['rate'][trend['Loss_Year'] <= last_developed_year]).size-1)) # Calculate geometric average of relative increases each year, use only developed years\n",
    "    trend['power'] = range((trend['rate'][trend['Loss_Year'] <= onlevel_to_year]).size-1,((trend['rate'][trend['Loss_Year'] <= onlevel_to_year]).size-1)-trend['rate'].size,-1) # Get # of years between each loss year and the year to onlevel to\n",
    "    trend['detrend_factor'] = trend['geom_avg'].pow(trend['power']) # Get detrend factor to apply to each year for on-levelling\n",
    "    trend['detrended'] = trend['Gross_Incurred_Indexed'] * trend['detrend_factor'] # Apply onleveling factor to get on-leveled mean claim amounts\n",
    "    print(trend) # Print resulting table\n",
    "    trend.to_csv(file_out, index=False)\n",
    "    print(\"Detrend table saved to \"+file_out)\n",
    "    return trend\n",
    "\n",
    "\n",
    "def apply_detrend_incurred(df, detrend_file):\n",
    "    trend = pd.read_csv(detrend_file)\n",
    "    # Merge table with detrend factors per year with the claims data set\n",
    "    df = df.merge(trend[['Loss_Year','detrend_factor']], left_on='Claim_Loss_Year', right_on='Loss_Year', how='left')\n",
    "    df['Gross_Incurred_Detrended'] = df['Gross_Incurred_Indexed'] * df['detrend_factor'] # Get onlevelled claim amounts for each individual claim\n",
    "    return df\n",
    "\n",
    "# Looks at most common relevant words in the free text fields Cause_Of_Loss_Description and Injury_Most_Serious_Description, groups similar words. These have been selected manually using basic diagnostics.\n",
    "# df = data frame with claims data\n",
    "def free_text_fields_manual(df):\n",
    "    df['Cause_Of_Loss_Description'] = df['Cause_Of_Loss_Description'].fillna(\"\") # replace NaNs with blanks for easier text processing\n",
    "    df['Injury_Most_Serious_Description'] = df['Injury_Most_Serious_Description'].fillna(\"\") # replace NaNs with blanks for easier text processing\n",
    "    df[\"free_text_fields\"] = [str(s1) + ' ' + str(s2) for s1, s2 in zip( df['Cause_Of_Loss_Description'], df[\"Injury_Most_Serious_Description\"] )] # Concatenate the two columns\n",
    "    # Convert to lower case for each claim and check if it contains one of the selected keywords. A boolean flag is created for each keyword.\n",
    "    df['strain'] = df[\"free_text_fields\"].str.lower().str.contains(\"strain\")\n",
    "    df['laceration'] = df[\"free_text_fields\"].str.lower().str.contains(\"lacerat\")\n",
    "    df['injury'] = df[\"free_text_fields\"].str.lower().str.contains(\"injury\")\n",
    "    df['body'] = df[\"free_text_fields\"].str.lower().str.contains(\"body\")\n",
    "    df['sprain'] = df[\"free_text_fields\"].str.lower().str.contains(\"sprain\")\n",
    "    df['pain'] = df[\"free_text_fields\"].str.lower().str.contains(\"pain\")\n",
    "    df['fracture'] = df[\"free_text_fields\"].str.lower().str.contains(\"fracture\") | df[\"free_text_fields\"].str.lower().str.contains(\"fractrure\")\n",
    "    df['contusion'] = df[\"free_text_fields\"].str.lower().str.contains(\"contusion\")\n",
    "    df['burn'] = df[\"free_text_fields\"].str.lower().str.contains(\"burn\")\n",
    "    df['crush'] = df[\"free_text_fields\"].str.lower().str.contains(\"crush\")\n",
    "    df['bruise'] = df[\"free_text_fields\"].str.lower().str.contains(\"bruis\")\n",
    "    df['abrasion'] = df[\"free_text_fields\"].str.lower().str.contains(\"abrasion\")\n",
    "    df['tear'] = df[\"free_text_fields\"].str.lower().str.contains(\" tear\") | df[\"free_text_fields\"].str.lower().str.contains(\" torn\")\n",
    "    df['cut'] = df[\"free_text_fields\"].str.lower().str.contains(\" cut\")\n",
    "    df['wound'] = df[\"free_text_fields\"].str.lower().str.contains(\"wound\")\n",
    "    df['bite'] = df[\"free_text_fields\"].str.lower().str.contains(\"bite\")\n",
    "    df['anxiety'] = df[\"free_text_fields\"].str.lower().str.contains(\"anxiety\")\n",
    "    df['broken'] = df[\"free_text_fields\"].str.lower().str.contains(\"broken\")\n",
    "    df['puncture'] = df[\"free_text_fields\"].str.lower().str.contains(\"puncture\")\n",
    "    df['shock'] = df[\"free_text_fields\"].str.lower().str.contains(\"shock\")\n",
    "    df['whiplash'] = df[\"free_text_fields\"].str.lower().str.contains(\"whiplash\")\n",
    "    df['fall'] = df[\"free_text_fields\"].str.lower().str.contains(\" fall\") | df[\"free_text_fields\"].str.lower().str.contains(\" fell\")\n",
    "    df['amputation'] = df[\"free_text_fields\"].str.lower().str.contains(\"amputat\")\n",
    "    return df\n",
    "\n",
    "# Groups remaining fixed text fields so that similar classes are grouped, and classes with insufficient datapoints bundled i.e. Injury_Mechanism, Body_Location, Employee_Occupation, Claim_ANZSIC_2006, Occupation_Name\n",
    "# df = data frame with claims data\n",
    "def text_fields_groupings(df):\n",
    "    # Injury_Mechanism\n",
    "    temp = pd.read_csv('xxxx/Injury_Mechanism_Grouped.csv')\n",
    "    df = df.merge(temp[['Injury_Mechanism','Injury_Mechanism_Grouped']], left_on='Injury_Mechanism', right_on='Injury_Mechanism', how='left') # Join with claims dataset\n",
    "    \n",
    "    # Body_Location\n",
    "    temp = pd.read_csv('xxxx/Body_Location_Grouped.csv')\n",
    "    df = df.merge(temp[['Body_Location','Body_Location_Grouped']], left_on='Body_Location', right_on='Body_Location', how='left') # Join with claims dataset\n",
    "    \n",
    "    # Employee_Occupation\n",
    "    temp = pd.read_csv('xxxx/Employee_Occupation_Grouped.csv')\n",
    "    df = df.merge(temp[['Employee_Occupation','Employee_Occupation_Grouped']], left_on='Employee_Occupation', right_on='Employee_Occupation', how='left')\n",
    "    \n",
    "    # Claim_ANZSIC_2006  \n",
    "    temp = pd.read_csv('xxxx/Claim_ANZSIC_2006_Grouped.csv')\n",
    "    df = df.merge(temp[['Claim_ANZSIC_2006','Claim_ANZSIC_2006_Grouped']], left_on='Claim_ANZSIC_2006', right_on='Claim_ANZSIC_2006', how='left')\n",
    "    \n",
    "    # Occupation_Name\n",
    "    temp = pd.read_csv('xxxx/Occupation_Name_Grouped.csv')\n",
    "    df = df.merge(temp[['Occupation_Name','Occupation_Name_Grouped']], left_on='Occupation_Name', right_on='Occupation_Name', how='left')\n",
    "    return df\n",
    "\n",
    "# Adds industry based on the industry code mapping\n",
    "# df = data frame with claims data\n",
    "# file = path to file with gross_incurreds at t30\n",
    "def add_industry(df, file):\n",
    "    df_IC = pd.read_excel(file, engine='pyxlsb') # Read industry code mapping\n",
    "    temp = df_IC.iloc[1] # There are blank rows before the header, hence we save the header row and remove the blanks\n",
    "    df_IC = df_IC.drop(df_IC.index[[0,1]]) # Remove first two rows\n",
    "    df_IC = df_IC.drop_duplicates() # Remove duplicate rows\n",
    "    df_IC.columns = temp # Set column headers\n",
    "    df_IC.columns = df_IC.columns.str.replace(\" \", \"_\", regex=True).str.replace(\"-\", \"_\", regex=True) # Clean up header names\n",
    "    df_IC =  df_IC.astype(str) # Make the entire dataframe consist of strings for eaiser industry code matching\n",
    "    df_IC['Class_Description_'] = df_IC['Class_Description_'].str.lower() # Convert to lower case\n",
    "    df_IC['Sub_division_Description'] = df_IC['Sub_division_Description'].str.lower()  # Convert to lower case\n",
    "    df_IC['Class_Description_30'] = df_IC['Class_Description_'].str[:30]  # Take first 30 characters, since the Claim_ANZSIC_2006 field is truncated to 30 chars\n",
    "    df['Employee_Occupation'] = df['Employee_Occupation'].str.lower() # Convert to lower case\n",
    "    df['Claim_ANZSIC_2006'] = df['Claim_ANZSIC_2006'].str.lower() # Convert to lower case\n",
    "    # Merge with claims data set based on Employee_Occupation, then on Claim_ANZSIC_2006\n",
    "    df_claim_occup = df.merge(df_IC[['Class_Description_','Sub_division_Description']].drop_duplicates(), left_on='Employee_Occupation', right_on='Class_Description_', how='left')\n",
    "    df_claim_occup = df_claim_occup.merge(df_IC[['Class_Description_30','Sub_division_Description']].drop_duplicates(['Class_Description_30']), left_on='Claim_ANZSIC_2006', right_on='Class_Description_30', how='left')\n",
    "    df_claim_occup['Sub_div'] = df_claim_occup.iloc[:,-3] # Third last column is the Sub_divisin_description that we're looking for, based on join with key Employee_Occupation\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Sub_div'] = df_claim_occup.iloc[(df_claim_occup['Sub_div'].isna()).values,-2] # If missing, take the Sub_divisin_description, based on join with key Claim_ANZSIC_2006\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div']=='-','Sub_div'] = np.NaN\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Sub_div'] = df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Claim_ANZSIC_2006'] # If still missing take Claim_ANZIC_2006\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div']=='-','Sub_div'] = np.NaN\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Sub_div'] = df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Employee_Occupation'] # If still missing take Employee_Occupation\n",
    "    temp = pd.read_csv('/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/data prep/Occupation_Grouped.csv')\n",
    "    df_claim_occup = df_claim_occup.merge(temp[['Sub_div','Occupation_Grouped']].drop_duplicates(), left_on='Sub_div', right_on='Sub_div', how='left')\n",
    "    df['Industry'] = df_claim_occup['Occupation_Grouped'] # Add column with grouped class to original dataframe\n",
    "    return df \n",
    "\n",
    "# Adds incurred at t30\n",
    "# df = data frame with claims data\n",
    "# file = path to file with gross_incurreds at t30\n",
    "def add_incurred_at_t30(df, file):\n",
    "    df_incurred_t30 = pd.read_excel(file) # Read file with incurred amounts at t+30\n",
    "    df['Claim_Number_C2'] =  'C2' + df['Claim_Number'].astype(str) # Add \"C2\" to claim numbers in data set to be able to map to t+30\n",
    "    df = df.merge(df_incurred_t30, left_on='Claim_Number_C2', right_on='claimno', how='left') # join with claims data set\n",
    "    df[\"incurred_t30_indexed\"] = df['indexation_factor'] * df['detrend_factor'] * df['gross_incurred_t30'] # apply wage indexation and detrending\n",
    "    return df\n",
    "\n",
    "# Adds SEIFA code based on worker postcode\n",
    "# df = data frame with claims data\n",
    "# file = path to file with postcode/SEIFA mapping\n",
    "def add_SEIFA(df, file):\n",
    "    df_postcodes = pd.read_excel(file)\n",
    "    df_postcodes = df_postcodes.rename(columns={\"SEIFA_Advantaged_Disadvantaged_Rank\":\"SEIFA\"})\n",
    "    df_postcodes['Postcode'] = df_postcodes['Postcode'].astype(str)\n",
    "    df_postcodes['SEIFA'] = df_postcodes['SEIFA'].astype(str)\n",
    "    df['Worker_Postcode'] = df['Worker_Postcode'].astype(str)\n",
    "    df = df.merge(df_postcodes[['Postcode','SEIFA']], left_on='Worker_Postcode', right_on='Postcode', how='left')\n",
    "    df['P_SEIFA'] = 'P_' + df['SEIFA'].astype(str)\n",
    "    return df\n",
    "  \n",
    "    \n",
    "def residual_data_prep_python(df):\n",
    "    \"\"\"\n",
    "    Output: (pandas DataFrame)\n",
    "    Dataframe with certain fields cleaned or added\n",
    "     _____________________________________________________\n",
    "    Parameters:\n",
    "    df: (pandas DataFrame) Dataframe with claims data to be cleaned\n",
    "    \"\"\"\n",
    "    # copy (input not modified in place)\n",
    "    df_processed_py = df.copy()\n",
    "\n",
    "    # NA treatment (PYTHON SPECIFIC preprocessing)\n",
    "    df_processed_py[\"Liability_Delay\"] = df_processed_py[\"Liability_Delay\"].fillna(0)\n",
    "    df_processed_py[\"Worker_Gender\"] = df_processed_py[\"Worker_Gender\"].replace(\"-\", \"M\")\n",
    "    df_processed_py[\"Worker_Marital_Status\"] = df_processed_py[\"Worker_Marital_Status\"].replace(\"-\", \"S\")\n",
    "    df_processed_py[\"Full/Part_Time_Flag\"] = df_processed_py[\"Full/Part_Time_Flag\"].replace(\"-\", \"F\")\n",
    "    df_processed_py[\"Worker_Age\"] = df_processed_py[\"Worker_Age\"].fillna(df_processed_py[\"Worker_Age\"].mean()) # IS THIS OK ?\n",
    "\n",
    "    df_processed_py[\"SEIFA\"] = df_processed_py[\"SEIFA\"].fillna(-1) # -1 treated as NAN for LGBM\n",
    "\n",
    "    # filter out newest dates (PYTHON SPECIFIC preprocessing) \n",
    "    #df_processed_py = df_processed_py[df_processed_py[\"Claim_Loss_Date\"]<\"2020\"]\n",
    "\n",
    "    # process the text data \n",
    "\n",
    "    # inputs and helper function for text processing \n",
    "    text_columns = ['Cause_Of_Loss_Description', \n",
    "                    'Agency_of_Accident', \n",
    "                    'Injury_Object_Involved', \n",
    "                    'Injury_Most_Serious_Description', \n",
    "                    'Injury_Nature', \n",
    "                    'Injury_Mechanism_Grouped']\n",
    "    splt = [',', '/', '(', ')', '-', '&', \"\\'\"]\n",
    "    exclude = ['AND', 'IN', 'TO', 'OF', 'OFF', 'ON', \"BY\"]\n",
    "\n",
    "    def clean_str(st, split_, excl):\n",
    "        \"\"\"\n",
    "        Output: (string)\n",
    "        st with removed words in excl, separators in split_\n",
    "        _____________________________________________________\n",
    "        Parameters:\n",
    "        st: (string) string of words to be processed\n",
    "        split_: (list) characters to be considered separators \n",
    "        excl: (list) words to be removed from string\n",
    "        \"\"\"\n",
    "        st = str(st)\n",
    "        for a in split_:\n",
    "            st = st.replace(a, ' ')\n",
    "        l = [s for s in st.split() if not s in excl or (len(s) == 1 and not s.isalpha())]\n",
    "        return \" \".join(l)\n",
    "\n",
    "    # text processing\n",
    "\n",
    "    # remove NA from Duty_Status\n",
    "    df_processed_py.loc[df_processed_py[\"Duty_Status\"].isnull(), \"Duty_Status\"] = 1\n",
    "\n",
    "    # fill NA\n",
    "    df_processed_py[\"incurred_t30_indexed\"].fillna(-9999, inplace=True)\n",
    "\n",
    "    # treat NA as empty characters in the text columns\n",
    "    df_processed_py[text_columns] = df_processed_py[text_columns].fillna(\"\")\n",
    "\n",
    "    # concatenate text fields into one column\n",
    "    text_fields_vector = zip(*[df_processed_py[col] for col in text_columns])\n",
    "    df_processed_py[\"concatenated_text\"] = [\"\".join(str(v)) for v in text_fields_vector]\n",
    "\n",
    "    # clean concatenated text with helper function\n",
    "    df_processed_py[\"concatenated_text\"] = df_processed_py[\"concatenated_text\"].apply(lambda x: clean_str(x, splt, exclude))\n",
    "\n",
    "\n",
    "    # convert categorical features to int for training\n",
    "    categorical_features = [\"Liability_Status_Grouped\",  \n",
    "                            \"Worker_Gender\", \n",
    "                            \"Worker_Marital_Status\", \n",
    "                            \"Risk_State\", \n",
    "                            \"Full/Part_Time_Flag\", \n",
    "                            \"Injury_Mechanism_Grouped\",\n",
    "                            \"Body_Location_Grouped\", \n",
    "                            \"Industry\", \n",
    "                            \"Occupation_Name_Grouped\", \n",
    "                            \"Claim_ANZSIC_2006_Grouped\", \n",
    "                            \"Employee_Occupation_Grouped\", \n",
    "                            \"IMA_Reviewed_Flag\", \n",
    "                            \"Weekly_Rate_Known\",\n",
    "                            \"Work_Resumed_Within_30days_Flag\"]\n",
    "\n",
    "    def cat_to_int(col):\n",
    "        \"\"\"\n",
    "        Output: (pandas Series)\n",
    "        column of int corresponding to category mapping\n",
    "        _____________________________________________________\n",
    "        Parameters:\n",
    "        col: (pandas Series) categorical variable column\n",
    "        \"\"\"\n",
    "        unique_val = np.unique(col.to_numpy())\n",
    "        d = {unique_val[i]:i for i in range(len(unique_val))}\n",
    "        return col.apply(lambda x: d[x])\n",
    "\n",
    "    # turn categorical variable into categorical int  \n",
    "    for cat_f in categorical_features:\n",
    "        df_processed_py[cat_f] = cat_to_int(df_processed_py[cat_f].astype(str))\n",
    "\n",
    "    # convert boolean to int \n",
    "    df_processed_py = df_processed_py.replace([True, False], [1, 0])\n",
    "    return df_processed_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d02e7467-4dbe-470e-a6fa-c80c14da9bf8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\n",
       "\u001B[0;32m<command-3647493134882365>\u001B[0m in \u001B[0;36m<cell line: 76>\u001B[0;34m()\u001B[0m\n",
       "\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     75\u001B[0m \u001B[0;31m# Test run\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 76\u001B[0;31m df = prepare_dataset(path_to_data = folder_name + 'Claim Severity Model Data - 20220525.xlsx',\n",
       "\u001B[0m\u001B[1;32m     77\u001B[0m                \u001B[0mpath_to_wage_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfolder_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'Wage Price Index 2021Q4.xlsx'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     78\u001B[0m                \u001B[0mpath_to_detrending_factors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfolder_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'detrend.csv'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m<command-3647493134882365>\u001B[0m in \u001B[0;36mprepare_dataset\u001B[0;34m(path_to_data, path_to_wage_index, path_to_detrending_factors, path_to_industry_codes, path_to_incurred_at_t30, path_to_SEIFA_codes, path_to_output)\u001B[0m\n",
       "\u001B[1;32m     24\u001B[0m     \u001B[0;32mif\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_extension\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'.xlsx'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     25\u001B[0m         \u001B[0;31m#print('Excel file')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mdf_claim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_excel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_to_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m     27\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# assume csv\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m     28\u001B[0m         \u001B[0;31m#print('CSV file')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    310\u001B[0m                 )\n",
       "\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36mread_excel\u001B[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001B[0m\n",
       "\u001B[1;32m    362\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExcelFile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    363\u001B[0m         \u001B[0mshould_close\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 364\u001B[0;31m         \u001B[0mio\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mExcelFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    365\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    366\u001B[0m         raise ValueError(\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path_or_buffer, engine, storage_options)\u001B[0m\n",
       "\u001B[1;32m   1189\u001B[0m                 \u001B[0mext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xls\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1190\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1191\u001B[0;31m                 ext = inspect_excel_format(\n",
       "\u001B[0m\u001B[1;32m   1192\u001B[0m                     \u001B[0mcontent_or_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1193\u001B[0m                 )\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36minspect_excel_format\u001B[0;34m(content_or_path, storage_options)\u001B[0m\n",
       "\u001B[1;32m   1068\u001B[0m         \u001B[0mcontent_or_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBytesIO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontent_or_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1069\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m-> 1070\u001B[0;31m     with get_handle(\n",
       "\u001B[0m\u001B[1;32m   1071\u001B[0m         \u001B[0mcontent_or_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_text\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m   1072\u001B[0m     ) as handle:\n",
       "\n",
       "\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n",
       "\u001B[1;32m    709\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    710\u001B[0m             \u001B[0;31m# Binary mode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0;32m--> 711\u001B[0;31m             \u001B[0mhandle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[0m\u001B[1;32m    712\u001B[0m         \u001B[0mhandles\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
       "\u001B[1;32m    713\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
       "\n",
       "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/dbfs/mnt/augiprojects-20220225workerscomp/raw data/Claim Severity Model Data - 20220525.xlsx'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)\n\u001B[0;32m<command-3647493134882365>\u001B[0m in \u001B[0;36m<cell line: 76>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[0;31m# Test run\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 76\u001B[0;31m df = prepare_dataset(path_to_data = folder_name + 'Claim Severity Model Data - 20220525.xlsx',\n\u001B[0m\u001B[1;32m     77\u001B[0m                \u001B[0mpath_to_wage_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfolder_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'Wage Price Index 2021Q4.xlsx'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     78\u001B[0m                \u001B[0mpath_to_detrending_factors\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfolder_name\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m'detrend.csv'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m<command-3647493134882365>\u001B[0m in \u001B[0;36mprepare_dataset\u001B[0;34m(path_to_data, path_to_wage_index, path_to_detrending_factors, path_to_industry_codes, path_to_incurred_at_t30, path_to_SEIFA_codes, path_to_output)\u001B[0m\n\u001B[1;32m     24\u001B[0m     \u001B[0;32mif\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfile_extension\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'.xlsx'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;31m#print('Excel file')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m         \u001B[0mdf_claim\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_excel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_to_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;31m# assume csv\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0;31m#print('CSV file')\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36mread_excel\u001B[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001B[0m\n\u001B[1;32m    362\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mExcelFile\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    363\u001B[0m         \u001B[0mshould_close\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 364\u001B[0;31m         \u001B[0mio\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mExcelFile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mio\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    365\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mio\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    366\u001B[0m         raise ValueError(\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path_or_buffer, engine, storage_options)\u001B[0m\n\u001B[1;32m   1189\u001B[0m                 \u001B[0mext\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"xls\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1190\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1191\u001B[0;31m                 ext = inspect_excel_format(\n\u001B[0m\u001B[1;32m   1192\u001B[0m                     \u001B[0mcontent_or_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1193\u001B[0m                 )\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/excel/_base.py\u001B[0m in \u001B[0;36minspect_excel_format\u001B[0;34m(content_or_path, storage_options)\u001B[0m\n\u001B[1;32m   1068\u001B[0m         \u001B[0mcontent_or_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBytesIO\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcontent_or_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1069\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1070\u001B[0;31m     with get_handle(\n\u001B[0m\u001B[1;32m   1071\u001B[0m         \u001B[0mcontent_or_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"rb\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstorage_options\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstorage_options\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_text\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1072\u001B[0m     ) as handle:\n\n\u001B[0;32m/databricks/python/lib/python3.9/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    709\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    710\u001B[0m             \u001B[0;31m# Binary mode\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 711\u001B[0;31m             \u001B[0mhandle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    712\u001B[0m         \u001B[0mhandles\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    713\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\n\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/dbfs/mnt/augiprojects-20220225workerscomp/raw data/Claim Severity Model Data - 20220525.xlsx'",
       "errorSummary": "<span class='ansi-red-fg'>FileNotFoundError</span>: [Errno 2] No such file or directory: '/dbfs/mnt/augiprojects-20220225workerscomp/raw data/Claim Severity Model Data - 20220525.xlsx'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_dataset(path_to_data = folder_name + 'unlabelled_data.csv',\n",
    "                    path_to_wage_index = folder_name + 'Wage Price Index 2021Q4.xlsx',\n",
    "                    path_to_detrending_factors = folder_name + 'detrend.csv',\n",
    "                    path_to_industry_codes = folder_name + 'WorkCover-WA-Industry-Codes-for-Recommended-Premium-Rates.xlsb',\n",
    "                    path_to_incurred_at_t30 = folder_name + 'Incurred_at_T30.xlsx',\n",
    "                    path_to_SEIFA_codes = folder_name + '2016 Census Fields by Postcode.xlsx',\n",
    "                    path_to_output = folder_name + 'unlabelled_data_prepped.csv'):\n",
    "    \"\"\"\n",
    "    Output: (pandas DataFrame)\n",
    "    Dataframe with added columns contained cleaned/enhanced data\n",
    "    _____________________________________________________\n",
    "    Parameters:\n",
    "    path_to_data: (string) path to csv or xlsx file with claims data\n",
    "    path_to_wage_index: (string) path to csv or xlsx file with claims data\n",
    "    path_to_detrending_factors: (string) path to csv file with detrending factors as generated by update_detrend_incurred()\n",
    "    path_to_industry_codes: (string) path to xlsb file with industry code mapping\n",
    "    path_to_incurred_at_t30: (string) path to xlsx file with incurred amounts at t30 per claim\n",
    "    path_to_SEIFA_codes: (string) path xlsx file with postcode to SEIFA mapping\n",
    "    path_to_output: (string) path to csv where output will be stored\n",
    "    \"\"\"\n",
    "    # Read file\n",
    "    temp, file_extension = os.path.splitext(path_to_data)\n",
    "    #print(\"File extension: \" + file_extension)\n",
    "    if(file_extension == '.xlsx'):\n",
    "        #print('Excel file')\n",
    "        df_claim = pd.read_excel(path_to_data)\n",
    "    else: # assume csv\n",
    "        #print('CSV file')\n",
    "        df_claim = pd.read_csv(path_to_data, low_memory=False)\n",
    "        \n",
    "    # Replace brackets and spaces in columns names by underscore\n",
    "    df_claim.columns = df_claim.columns.str.replace(\"[ ]\", \"_\", regex=True)\n",
    "    df_claim.columns = df_claim.columns.str.replace(\"[()]\", \"\", regex=True)\n",
    " \n",
    "    # Index wages and losses using wage index data set\n",
    "    df_claim = wage_indexation(df = df_claim, file=path_to_wage_index)\n",
    "    # Convert dates and calculate relevant time differences / delays, also convert wages to weekly rates\n",
    "    df_claim = clean_dates(df = df_claim)\n",
    "  \n",
    "    # Detrend gross incurred losses (assume exponential growth) by on-leveling to a recent point in time\n",
    "    #calibrate_detrend_incurred(df_claim, 2021, 2019, path_to_detrending_factors)\n",
    "    df_claim = apply_detrend_incurred(df_claim, path_to_detrending_factors)\n",
    " \n",
    "    ### Categorical variable preparation ###    \n",
    "    # Liability status - create bucket '-' for missing data and rare classes\n",
    "    df_claim['Liability_Status_Grouped'] = df_claim['Liability_Status']\n",
    "    df_claim.loc[~ df_claim['Liability_Status'].isin(['A','D','P','V','W','I']), 'Liability_Status_Grouped'] = \"-\"\n",
    "\n",
    "    # Cause_Of_Loss_Description & Injury_Most_Serious_Description - Free text field analysis - extract most common revelant words\n",
    "    df_claim = free_text_fields_manual(df=df_claim)\n",
    "\n",
    "    # Individual categorical variables - Injury_Mechanism, Body_Location, ... => group similar classes and create bucket for missing data and rare classes (<100 occurrences)\n",
    "    df_claim = text_fields_groupings(df=df_claim)\n",
    "    \n",
    "    # Map occupation to industry\n",
    "    df_claim = add_industry(df=df_claim, file = path_to_industry_codes)\n",
    "\n",
    "    # Add gross incurred at t+30 where available + onlevel\n",
    "    df_claim = add_incurred_at_t30(df=df_claim, file = path_to_incurred_at_t30)\n",
    "\n",
    "    # Add SEIFA to postcodes\n",
    "    df_claim = add_SEIFA(df=df_claim, file = path_to_SEIFA_codes)    \n",
    "    df_claim = df_claim.sort_values(by=\"Claim_Loss_Date_Num\").reset_index(drop=True)\n",
    "    #print(df_claim.head(100))\n",
    "    \n",
    "    # Residual data preparation, mostly filtering out blanks\n",
    "    df_claim = residual_data_prep_python(df_claim)\n",
    "\n",
    "    # Save new data set as CSV\n",
    "    df_claim.to_csv(path_to_output, index=False)\n",
    "        \n",
    "    return df_claim\n",
    "\n",
    "\n",
    "# Test run\n",
    "df = prepare_dataset(path_to_data = folder_name + 'Claim Severity Model Data - 20220525.xlsx',\n",
    "               path_to_wage_index = folder_name + 'Wage Price Index 2021Q4.xlsx',\n",
    "               path_to_detrending_factors = folder_name + 'detrend.csv',\n",
    "               path_to_industry_codes = folder_name + 'WorkCover-WA-Industry-Codes-for-Recommended-Premium-Rates.xlsb',\n",
    "               path_to_incurred_at_t30 = folder_name + 'Incurred_at_T30.xlsx',\n",
    "               path_to_SEIFA_codes = folder_name + '2016 Census Fields by Postcode.xlsx',\n",
    "               path_to_output = folder_name + 'unlabelled_data_prepped.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffe5f664-f529-4a99-9a4e-95771b5cb99b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">38171\n",
       "38171\n",
       "28300.404620359594\n",
       "-9999.0\n",
       "0.5063791883890912\n",
       "27135.427378828852\n",
       "19178    20362.187884\n",
       "Name: incurred_t30_indexed, dtype: float64\n",
       "33278    1213.943668\n",
       "Name: incurred_t30_indexed, dtype: float64\n",
       "1   -9999.0\n",
       "Name: incurred_t30_indexed, dtype: float64\n",
       "Out[21]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">38171\n38171\n28300.404620359594\n-9999.0\n0.5063791883890912\n27135.427378828852\n19178    20362.187884\nName: incurred_t30_indexed, dtype: float64\n33278    1213.943668\nName: incurred_t30_indexed, dtype: float64\n1   -9999.0\nName: incurred_t30_indexed, dtype: float64\nOut[21]: </div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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",
       "datasetInfos": [],
       "metadata": {
        "imageDimensions": {
         "height": 274,
         "width": 372
        }
       },
       "removedWidgets": [],
       "type": "image"
      },
      "image/png": {
       "height": 274,
       "width": 372
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;AxesSubplot:xlabel=&#39;Gross_Incurred_Indexed&#39;&gt;</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;AxesSubplot:xlabel=&#39;Gross_Incurred_Indexed&#39;&gt;</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##############\n",
    "#### REMOVE ##\n",
    "##############\n",
    "# Diagnostics \n",
    "print(len(df))\n",
    "print(len(df[~df['Gross_Incurred_Indexed'].isnull()]))\n",
    "print(df['incurred_t30_indexed'][df['incurred_t30_indexed']>0].mean())\n",
    "print(df['incurred_t30_indexed'][df['incurred_t30_indexed']<0].mean())\n",
    "print(len(df['incurred_t30_indexed'][df['incurred_t30_indexed']<0])/ len(df))\n",
    "print(df['Gross_Incurred_Indexed'].mean())\n",
    "print(df['incurred_t30_indexed'][df['Claim_Number']=='3192885'])\n",
    "print(df['incurred_t30_indexed'][df['Claim_Number']=='3589074'])\n",
    "print(df['incurred_t30_indexed'][df['Claim_Number']=='2841418'])\n",
    "df.plot('Gross_Incurred_Indexed', 'incurred_t30_indexed', style='o')\n",
    "# df.to_csv(folder_name +'reference_preprocess_data_2408.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "011118d2-fc2a-483e-9177-0ff4b879d58c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # To recalibrate the detrending on a given dataset:\n",
    "def update_detrend_incurred(path_to_data = folder_name + 'Claim Severity Model Data - 20220525.xlsx',\n",
    "                              path_to_wage_index = folder_name + 'Wage Price Index 2021Q4.xlsx',\n",
    "                              path_to_detrending_factors = folder_name + 'detrend_update.csv',\n",
    "                              max_developed_year = 2019,\n",
    "                              year_to_onlevel_to = 2021):  \n",
    "                           \n",
    "    # Read file\n",
    "    temp, file_extension = os.path.splitext(path_to_data)\n",
    "    if(file_extension == '.xlsx'):\n",
    "        df_claim = pd.read_excel(path_to_data)\n",
    "    else: # assume csv\n",
    "         df_claim = pd.read_csv(path_to_data)\n",
    "    # Replace brackets and spaces in columns names by underscore\n",
    "    df_claim.columns = df_claim.columns.str.replace(\"[ ]\", \"_\", regex=True)\n",
    "    df_claim.columns = df_claim.columns.str.replace(\"[()]\", \"\", regex=True)\n",
    "\n",
    "    # Index wages and losses using wage index data set\n",
    "    df_claim = wage_indexation(df = df_claim, file=path_to_wage_index)\n",
    "    # Convert dates and calculate relevant time differences / delays, also convert wages to weekly rates\n",
    "    df_claim = clean_dates(df = df_claim)\n",
    "    trend = calibrate_detrend_incurred(df_claim, year_to_onlevel_to, max_developed_year, path_to_detrending_factors)\n",
    "    return trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af7bfada-ac89-4ba0-a428-cd898ae2f71f",
     "showTitle": true,
     "title": "Update the grouping of text fields in the data preprocessing - adjust functions, uncomment and rerun this cell to update"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Groups remaining fixed text fields so that similar classes are grouped, and classes with insufficient datapoints bundled i.e. Injury_Mechanism, Body_Location, Employee_Occupation, Claim_ANZSIC_2006, Occupation_Name\n",
    "# df = data frame with claims data\n",
    "def text_fields_groupings_train(df):\n",
    "    # Injury_Mechanism\n",
    "    temp = df.groupby('Injury_Mechanism',as_index=False)[\"Claim_Number\"].count()\n",
    "    temp['Injury_Mechanism_Grouped'] = temp['Injury_Mechanism'] \n",
    "    temp.loc[temp['Injury_Mechanism'].isin(['HITTING STATIONARY OBJECTS','HITTING MOVING OBJECTS','BEING HIT BY MOVING OBJECTS']),'Injury_Mechanism_Grouped'] = 'HIT OBJECT' # Group these as they have similar loss profile and are semantically similar\n",
    "    temp.loc[temp['Injury_Mechanism'].isin(['MUSCULAR STRESS WHILE HANDLING OBJECTS OTHER THAN LIFTING, CARRYING OR PUTTING DOWN','MUSCULAR STRESS WHILE LIFTING, CARRYING OR PUTTING DOWN OBJECTS']),'Injury_Mechanism_Grouped'] = 'MUSCULAR STRESS' # Group these as they have similar loss profile and are semantically similar\n",
    "    temp.loc[temp['Claim_Number'] < 210,'Injury_Mechanism_Grouped'] = 'OTHER' # Group all classes with insufficient datapoints\n",
    "    temp.to_csv('/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/data prep/Injury_Mechanism_Grouped.csv', index=False)\n",
    "    df = df.merge(temp[['Injury_Mechanism','Injury_Mechanism_Grouped']], left_on='Injury_Mechanism', right_on='Injury_Mechanism', how='left') # Join with claims dataset\n",
    "    \n",
    "    # Body_Location\n",
    "    temp = df.groupby('Body_Location',as_index=False)[\"Claim_Number\"].count()\n",
    "    temp['Body_Location_Grouped'] = temp['Body_Location']   \n",
    "    temp.loc[temp['Body_Location'].isin(['EYE - UNSPECIFIED','EYEBALL','EYE - OTHER AND MULTIPLE']),'Body_Location_Grouped'] = 'EYE' # Group these as they have similar loss profile and are semantically similar\n",
    "    temp.loc[temp['Body_Location'].isin(['FINGERS','HAND','THUMB','HAND, FINGERS AND THUMB - OTHER AND MULTIPLE']),'Body_Location_Grouped'] = 'HAND'\n",
    "    temp.loc[temp['Body_Location'].isin(['HEAD - UNSPECIFIED LOCATIONS','CRANIUM','FACE','EAR']),'Body_Location_Grouped'] = 'HEAD'\n",
    "    temp.loc[temp['Body_Location'].isin(['NECK AND SHOULDER','NECK - OTHER AND MULTIPLE']),'Body_Location_Grouped'] = 'NECK - MULTIPLE'\n",
    "    temp.loc[temp['Body_Location'].isin(['FOOT','LOWER LEG','TOES']),'Body_Location_Grouped'] = 'FOOT'\n",
    "    temp.loc[temp['Claim_Number'] < 200,'Body_Location_Grouped'] = 'OTHER' # Group all classes with insufficient datapoints\n",
    "    temp.to_csv('/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/data prep/Body_Location_Grouped.csv', index=False)\n",
    "    df = df.merge(temp[['Body_Location','Body_Location_Grouped']], left_on='Body_Location', right_on='Body_Location', how='left') # Join with claims dataset\n",
    "    \n",
    "    # Employee_Occupation\n",
    "    temp = df.groupby('Employee_Occupation',as_index=False)[\"Claim_Number\"].count()\n",
    "    temp['Employee_Occupation_Grouped'] = temp['Employee_Occupation'] \n",
    "    temp.loc[temp['Claim_Number'] < 100,'Employee_Occupation_Grouped'] = 'OTHER' # Group all classes with insufficient datapoints\n",
    "    temp.to_csv('/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/data prep/Employee_Occupation_Grouped.csv', index=False)\n",
    "    df = df.merge(temp[['Employee_Occupation','Employee_Occupation_Grouped']], left_on='Employee_Occupation', right_on='Employee_Occupation', how='left')\n",
    "    \n",
    "    # Claim_ANZSIC_2006\n",
    "    temp = df.groupby('Claim_ANZSIC_2006',as_index=False)[\"Claim_Number\"].count()\n",
    "    temp['Claim_ANZSIC_2006_Grouped'] = temp['Claim_ANZSIC_2006']\n",
    "    temp.loc[temp['Claim_Number'] < 100,'Claim_ANZSIC_2006_Grouped'] = 'OTHER' # Group all classes with insufficient datapoints\n",
    "    temp.to_csv('/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/data prep/Claim_ANZSIC_2006_Grouped.csv', index=False)\n",
    "    df = df.merge(temp[['Claim_ANZSIC_2006','Claim_ANZSIC_2006_Grouped']], left_on='Claim_ANZSIC_2006', right_on='Claim_ANZSIC_2006', how='left')\n",
    "    \n",
    "    # Occupation_Name\n",
    "    temp = df.groupby('Occupation_Name',as_index=False)[\"Claim_Number\"].count()\n",
    "    temp['Occupation_Name_Grouped'] = temp['Occupation_Name'] \n",
    "    temp.loc[temp['Claim_Number'] < 100,'Occupation_Name_Grouped'] = 'OTHER' # Group all classes with insufficient datapoints\n",
    "    temp.to_csv('/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/data prep/Occupation_Name_Grouped.csv', index=False)\n",
    "    df = df.merge(temp[['Occupation_Name','Occupation_Name_Grouped']], left_on='Occupation_Name', right_on='Occupation_Name', how='left')\n",
    "    return df\n",
    "\n",
    "\n",
    "# Adds industry based on the industry code mapping\n",
    "# df = data frame with claims data\n",
    "# file = path to file with gross_incurreds at t30\n",
    "def add_industry_train(df, file):\n",
    "    df_IC = pd.read_excel(file, engine='pyxlsb') # Read industry code mapping\n",
    "    temp = df_IC.iloc[1] # There are blank rows before the header, hence we save the header row and remove the blanks\n",
    "    df_IC = df_IC.drop(df_IC.index[[0,1]]) # Remove first two rows\n",
    "    df_IC = df_IC.drop_duplicates() # Remove duplicate rows\n",
    "    df_IC.columns = temp # Set column headers\n",
    "    df_IC.columns = df_IC.columns.str.replace(\" \", \"_\", regex=True).str.replace(\"-\", \"_\", regex=True) # Clean up header names\n",
    "    df_IC =  df_IC.astype(str) # Make the entire dataframe consist of strings for eaiser industry code matching\n",
    "    df_IC['Class_Description_'] = df_IC['Class_Description_'].str.lower() # Convert to lower case\n",
    "    df_IC['Sub_division_Description'] = df_IC['Sub_division_Description'].str.lower()  # Convert to lower case\n",
    "    df_IC['Class_Description_30'] = df_IC['Class_Description_'].str[:30]  # Take first 30 characters, since the Claim_ANZSIC_2006 field is truncated to 30 chars\n",
    "    df['Employee_Occupation'] = df['Employee_Occupation'].str.lower() # Convert to lower case\n",
    "    df['Claim_ANZSIC_2006'] = df['Claim_ANZSIC_2006'].str.lower() # Convert to lower case\n",
    "    # Merge with claims data set based on Employee_Occupation, then on Claim_ANZSIC_2006\n",
    "    df_claim_occup = df.merge(df_IC[['Class_Description_','Sub_division_Description']].drop_duplicates(), left_on='Employee_Occupation', right_on='Class_Description_', how='left')\n",
    "    df_claim_occup = df_claim_occup.merge(df_IC[['Class_Description_30','Sub_division_Description']].drop_duplicates(['Class_Description_30']), left_on='Claim_ANZSIC_2006', right_on='Class_Description_30', how='left')\n",
    "    df_claim_occup['Sub_div'] = df_claim_occup.iloc[:,-3] # Third last column is the Sub_divisin_description that we're looking for, based on join with key Employee_Occupation\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Sub_div'] = df_claim_occup.iloc[(df_claim_occup['Sub_div'].isna()).values,-2] # If missing, take the Sub_divisin_description, based on join with key Claim_ANZSIC_2006\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div']=='-','Sub_div'] = np.NaN\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Sub_div'] = df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Claim_ANZSIC_2006'] # If still missing take Claim_ANZIC_2006\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div']=='-','Sub_div'] = np.NaN\n",
    "    df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Sub_div'] = df_claim_occup.loc[df_claim_occup['Sub_div'].isna(),'Employee_Occupation'] # If still missing take Employee_Occupation\n",
    "    # Pivot table to check how often each class appears\n",
    "    temp = df_claim_occup.groupby('Sub_div',as_index=False)[\"Claim_Number\"].count()\n",
    "    temp['Occupation_Grouped'] = temp['Sub_div'] \n",
    "    temp.loc[temp['Claim_Number'] < 50,'Occupation_Grouped'] = 'OTHER' # Group all classes with insufficient data points\n",
    "    temp.to_csv('xxxx/Occupation_Grouped.csv', index=False)\n",
    "    df_claim_occup = df_claim_occup.merge(temp[['Sub_div','Occupation_Grouped']].drop_duplicates(), left_on='Sub_div', right_on='Sub_div', how='left')\n",
    "    df['Industry'] = df_claim_occup['Occupation_Grouped'] # Add column with grouped class to original dataframe\n",
    "    return df \n",
    "\n",
    "## Example run to update groupings\n",
    "#df_claim = pd.read_excel('/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/Claim Severity Model Data - 20220525.xlsx')\n",
    "#df_claim.columns = df_claim.columns.str.replace(\"[ ]\", \"_\", regex=True)\n",
    "#df_claim.columns = df_claim.columns.str.replace(\"[()]\", \"\", regex=True)\n",
    "#text_fields_groupings_train(df_claim)\n",
    "#add_industry_train(df_claim, '/dbfs/mnt/augiprojects-20220225workerscomp/for sharing/WorkCover-WA-Industry-Codes-for-Recommended-Premium-Rates.xlsb')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "functions_data_prep (2)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
