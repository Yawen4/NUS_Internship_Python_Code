{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77643a05-5610-4bbc-927b-0bf9456121a1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "apt update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d01ff653-b794-49fb-94be-fbbb69e29d3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "apt-get install -y unoconv libreoffice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e2d38b1-e3e6-41ce-b668-10938ca43b4c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#List of dependencies\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from docx import Document\n",
    "from docx.oxml import parse_xml\n",
    "import subprocess\n",
    "import requests\n",
    "import io\n",
    "from docx.opc.constants import CONTENT_TYPE as CT\n",
    "from docx.oxml import parse_xml\n",
    "from docx.oxml.ns import nsdecls\n",
    "from docx.shared import Inches\n",
    "PATH = 'xxxx'\n",
    "PATH1 = 'xxxx'\n",
    "PATH2 = 'xxxx'\n",
    "PATH2 = 'xxxx'\n",
    "\n",
    "\n",
    "if not('IS_FIRST_NOTEBOOK_RUN' in locals()):\n",
    "#     os.system(\"apt-get -f -y install xxxxx\")\n",
    "    IS_FIRST_NOTEBOOK_RUN = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af9c0c5b-8e65-419a-a555-38f5d266fdd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "################################### ONE OFF SETUP ###################################\n",
    "#####################################################################################\n",
    "#Mounting the blob storage for dengue documents\n",
    "storage_name=\"xxxx\"\n",
    "container_name=\"xxxx\"\n",
    "blobkey=\"xxxx\"\n",
    "\n",
    "blobconf = \"fs.azure.account.key.\"+storage_name+\".blob.core.windows.net\"\n",
    "if not any(mount.mountPoint == \"/mnt/\"+storage_name+ \"/\" +container_name for mount in dbutils.fs.mounts()):\n",
    "    print('nothing mounted')\n",
    "    try:\n",
    "        dbutils.fs.mount(\n",
    "          source = \"wasbs://\"+container_name+\"@\"+storage_name+\".blob.core.windows.net\",\n",
    "          mount_point = \"/mnt/\"+storage_name+ \"/\" +container_name,\n",
    "          extra_configs = {blobconf:blobkey})\n",
    "    except Exception as e:\n",
    "        print(\"already mounted. Try to unmount first\")\n",
    "\n",
    "PATH = '/dbfs/mnt/'+storage_name+'/'+container_name +'/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8abf0d53-29a2-43d1-9bb5-ad413d281897",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Email body \n",
    "email_body = '''\n",
    "<p>Dear our valuable customers,</p><br>\n",
    "<p>Congratulations, your application for purchasing a vehicle insurance product from Zurich Asuransi Indonesia has been approved.</p><br>\n",
    "<p>Your vehicleâ€™s license plate: {text}</p><br>\n",
    "<p>We attach the results of the assessment that has been verified.</p>\n",
    "<p>Should you need further information on your vehicle, please contact your Zurich agent.</p><br>\n",
    "<p>PT Zurich Asuransi Indonesia Tbk is licensed and registered by the Financial Services Authority (OJK).</p>\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ead3ecf0-2529-46cd-afaf-b4370b5eb165",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def replace_placeholders(doc, replacements):\n",
    "    page_number = 1\n",
    "    for paragraph in doc.paragraphs:\n",
    "        if page_number <= 2:\n",
    "            for key, value in replacements.items():\n",
    "                if key in paragraph.text:\n",
    "                    paragraph.text = paragraph.text.replace(key, value)\n",
    "                    \n",
    "    for table in doc.tables:\n",
    "        for row in table.rows:\n",
    "            for cell in row.cells:\n",
    "                for key, value in replacements.items():\n",
    "                    if key in cell.text:\n",
    "                        cell.text = cell.text.replace(key, value)\n",
    "\n",
    "    return doc\n",
    "\n",
    "def fill_images_in_table(doc, image_folder):\n",
    "    image_files = os.listdir(image_folder)\n",
    "    table = doc.tables[0]  # Get the first table in the document\n",
    "\n",
    "    row_index = 2  # Index of the third row (0-based indexing)\n",
    "    cell_index = 0  # Index of the first cell in the row (0-based indexing)\n",
    "\n",
    "    image_counter = 0  # Counter to keep track of the number of inserted images\n",
    "\n",
    "    while image_counter < len(image_files):\n",
    "        if cell_index >= len(table.columns):\n",
    "            # Move to the next row if the current row is filled\n",
    "            row_index += 1\n",
    "            cell_index = 0\n",
    "\n",
    "        if row_index >= len(table.rows):\n",
    "            # Break if we have exhausted all rows in the table\n",
    "            break\n",
    "\n",
    "        cell = table.cell(row_index, cell_index)\n",
    "        image_path = os.path.join(image_folder, image_files[image_counter])\n",
    "        cell.text = \"\"\n",
    "\n",
    "        # Add the image to the cell\n",
    "        cell_paragraph = cell.paragraphs[0]\n",
    "        run = cell_paragraph.add_run()\n",
    "        run.add_picture(image_path, width=Inches(1.5), height=Inches(1.5))\n",
    "\n",
    "        image_counter += 1\n",
    "        cell_index += 1\n",
    "\n",
    "        if cell_index % 4 == 0:\n",
    "            # Move to the next row after inserting four images in the current row\n",
    "            row_index += 1\n",
    "            cell_index = 0\n",
    "\n",
    "    return doc\n",
    "\n",
    "\n",
    "def save_docx_to_file(doc, file_path):\n",
    "    buffer = io.BytesIO()\n",
    "    doc.save(buffer)\n",
    "    buffer.seek(0)\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        f.write(buffer.read())\n",
    "\n",
    "def convert_to_pdf(input_path, output_path):\n",
    "        subprocess.run(['unoconv', '-f', 'pdf', '-o', output_path, input_path], check=True)\n",
    "        #subprocess.run(['unoconv', '-f', 'pdf', '-o', output_path, input_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d70092d6-f5b0-4b95-bba5-826d9dd88828",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_camcom_review_completed = pd.read_csv('xxxx'+ 'df_camcom_review_completed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92a81c87-06b7-4a8c-9d0f-c834d4821eef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# every time a new blob is uploaded or modified\n",
    "# read all the files \n",
    "#filename = dbutils.widgets.get('filename')\n",
    "#camcom-sftp/camcom-data/zurichidsa_camcom_id.csv\n",
    "\n",
    "file_list = os.listdir(PATH1 + \"camcom-sftp/camcom-data\")\n",
    "import pickle\n",
    "with open(PATH +'file_list_before.pickle', 'rb') as file:\n",
    "    file_list_before = pickle.load(file)\n",
    "\n",
    "for i in file_list:\n",
    "    if i not in file_list_before:\n",
    "        print(i)\n",
    "        if '_review_completed.csv' in str(i):\n",
    "            file_list_before.append(i)\n",
    "            inspection_id = i.split('_')[0]\n",
    "            print(inspection_id)\n",
    "    \n",
    "        # if inspection_id:\n",
    "            df_merged = df_camcom_review_completed[df_camcom_review_completed['Inspection ID'] == inspection_id].reset_index()\n",
    "            df_merged['Type of Damages'] = df_merged['Type of Damages'].apply(lambda x: '' if x == '-' else x)\n",
    "\n",
    "            df = df_merged[['Damaged Part','Type of Damages','Action']].copy()\n",
    "            grouped = df.groupby(['Damaged Part', 'Type of Damages'])['Action'].apply(list).reset_index()\n",
    "            print(grouped)\n",
    "            repair_list = []\n",
    "            replace_list = []\n",
    "\n",
    "            for _, row in df.iterrows():\n",
    "                damaged_part = row['Damaged Part']\n",
    "                damage_type = row['Type of Damages']\n",
    "                action = row['Action']\n",
    "\n",
    "                action_text = f'{damaged_part} / {damage_type}'\n",
    "\n",
    "                if action == 'Repair':\n",
    "                    repair_list.append(action_text)\n",
    "                \n",
    "                if action == 'Replace':\n",
    "                    replace_list.append(action_text)\n",
    "\n",
    "            repair_list = repair_list\n",
    "            replace_list = replace_list\n",
    "\n",
    "            repair_list = '\\n'.join(repair_list)\n",
    "            replace_list = '\\n'.join(replace_list)\n",
    "            print('repair_list:', repair_list)\n",
    "            print('replace_list:', replace_list)\n",
    "\n",
    "            template_path = \"xxxx/template/ZSurvey Assessment Result.docx\"\n",
    "            image_folder = \"xxxxsftp/images/\" + inspection_id\n",
    "            print(image_folder)\n",
    "            PATH = \"xxxx/template/\"\n",
    "            doc = Document(template_path)\n",
    "\n",
    "            temp_df = pd.read_csv(\"xxxx\" + inspection_id +'_review_completed.csv')\n",
    "            reviewd_date = temp_df['Review Completed Date'][0]\n",
    "\n",
    "            file_name_doc = PATH2 + temp_df['Licence Plate'][0] + \".docx\"\n",
    "            file_name_pdf = PATH2 + temp_df['Licence Plate'][0] + \".pdf\"\n",
    "            replacements = {\n",
    "            \"{{placeholder1}}\": temp_df['Licence Plate'][0],\n",
    "            \"{{placeholder2}}\": reviewd_date,\n",
    "            \"{{placeholder3}}\": repair_list,\n",
    "            \"{{placeholder4}}\": replace_list\n",
    "            }\n",
    "\n",
    "            replace_placeholders(doc, replacements)\n",
    "            fill_images_in_table(doc,image_folder)\n",
    "\n",
    "            save_docx_to_file(doc, file_name_doc)\n",
    "            convert_to_pdf(file_name_doc, file_name_pdf)\n",
    "            email_body = email_body.replace(\"{text}\", temp_df['Licence Plate'][0])\n",
    "\n",
    "            text_file = open(PATH2 + temp_df['Licence Plate'][0] + \".txt\", \"w\")\n",
    "            n = text_file.write(email_body)\n",
    "            text_file.close()\n",
    "        # else:\n",
    "        #     pass\n",
    "\n",
    "        else:\n",
    "            file_list_before.append(i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "55b08490-62f7-4df8-91e4-4662583ab80a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(PATH +'file_list_before.pickle', 'wb') as file:\n",
    "    pickle.dump(file_list_before, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c519377c-0791-4e99-aead-484e46dce9bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# file_list_before = os.listdir(PATH1+'camcom-sftp/camcom-data')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3683119809639965,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Email_notification (2)",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
